{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4YD3fUQ28mW"
      },
      "source": [
        "# Práctica 2\n",
        "\n",
        "Ahora es tu turno de construir un detector de objetos.\n",
        "\n",
        "## Ejercicio obligatorio (5 puntos)\n",
        "\n",
        "A continuación se listan una serie de datasets que están disponibles en Kaggle o en otras fuentes. El ejercicio que tenéis que realizar obligatoriamente consiste en elegir uno de esos datasets (también podéis elegir otro que vosotros prefiráis) y construir un modelo siguiendo las instrucciones proporcionadas en el notebook de instrucciones. Deberás completar los ejercicios planteados en el informe de prácticas, ten en cuenta que en los ejercicios planteados puedes tener que realizar algún cambio en el código proporcionado.\n",
        "\n",
        "- [Kangaroo dataset](https://github.com/experiencor/kangaroo). En caso de utilizar este dataset tienes que eliminar la anotación y la imagen 00090 ya que está corrupta.\n",
        "- [Racoon dataset](https://github.com/datitran/raccoon_dataset).\n",
        "- [Wheat detection](https://www.kaggle.com/c/global-wheat-detection/data).\n",
        "- [Winegrape Detection Dataset](https://github.com/thsant/wgisd).\n",
        "\n",
        "También puedes elegir cualquiera de los datasets disponibles en [50+ Object Detection Datasets from different industry domains](https://towardsai.net/p/computer-vision/50-object-detection-datasets-from-different-industry-domains) o utilizar un dataset de otra fuente. **Ojo.** Cuidado con el tamaño de los datasets, si contienen muchas imágenes el proceso de entrenamiento puede ser muy largo.\n",
        "\n",
        "## Ejercicios opcionales\n",
        "\n",
        "A continuación se listan una serie de ejercicios adicionales. Para que estos ejercicios sean tenidos en cuenta han de ser documentadas en el propio notebook, dando una explicación de lo que se está haciendo. Debes crear un nuevo notebook para cada uno de los ejercicios que realices, completar los ejercicios planteados en el informe y guardarlo en este repositorio de GitHub.\n",
        "\n",
        "Es posible utilizar gran parte de la funcionalidad de FastAI que vimos para clasificadores de imágenes con la librería IceVision.\n",
        "- *Busqueda learning rate* (0.5 puntos). Busca el learning rate más adecuado para entrenar tu modelo con el *learning rate finder*.\n",
        "- *Callbacks* (0.5 puntos). Es posible utilizar los callbacks de FastAI. Utiliza dichos callbacks para aplicar *early stopping* y guardar el mejor modelo que se encuentre durante el proceso de entrenamiento.\n",
        "\n",
        "IceVision no solo permite entrenar modelos con la arquitectura de Faster RCNN sino también con otras muchas.\n",
        "- *Entrena con otra arquitectura* (0.5 puntos). Entrena un modelo usando una arquitectura diferente a Faster RCNN.\n",
        "- *Backbone* (0.5 puntos). En el ejemplo hemos visto cómo entrenar un modelo Faster RCNN con el backbone ResNet 18, entrena un nuevo modelo utilizando un backbone distinto.\n",
        "- *Ensemble* (1 punto). Una vez entrenados varios modelos crea un ensemble de los mismos para realizar predicciones. Para eliminar aquellos bounding boxes que se superpongan en la predicción usa la técnica de [Non maximum suppression](https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/).\n",
        "\n",
        "Crea un space de HugginFace con el modelo que has creado (1 punto).\n",
        "\n",
        "Además de la librería IceVision existen otras librerías para entrenar modelos con arquitecturas que no están incluidas en IceVision. Elige una de las siguientes librerías y entrena un modelo con ella (1 punto):\n",
        "- [YOLO v3 o v4](https://github.com/AlexeyAB/darknet)\n",
        "- [FCOS](https://github.com/xuannianz/keras-fcos)\n",
        "- [FSAF](https://github.com/xuannianz/FSAF)\n",
        "- [YOLO v5](https://github.com/ultralytics/yolov5)\n",
        "- [YOLO v8](https://learnopencv.com/ultralytics-yolov8/)\n",
        "\n",
        "También puedes elegir otra librería que busques por tu cuenta con algún algoritmo que no esté disponible en las librerías anteriores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWs6kssy28mc"
      },
      "source": [
        "Al finalizar, recuerda guardar los cambios en GitHub utilizando la opción Archivo -> Guardar una copia en GitHub."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9 python3.9-dev python3.9-distutils libpython3.9-dev\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\n",
        "\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR3syDPN2-Y-",
        "outputId": "191f57fb-2d2b-47b0-c1d7-f07ad14201be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [808 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,135 kB]\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,974 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,691 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [61.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,176 kB]\n",
            "Fetched 11.6 MB in 4s (3,186 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.9 is already the newest version (3.9.19-1+jammy1).\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9 python3.9-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9 libpython3.9-dev python3.9-dev python3.9-distutils\n",
            "  python3.9-lib2to3\n",
            "0 upgraded, 5 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 7,350 kB of archives.\n",
            "After this operation, 27.7 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9 amd64 3.9.19-1+jammy1 [1,903 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-dev amd64 3.9.19-1+jammy1 [4,627 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-dev amd64 3.9.19-1+jammy1 [500 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-lib2to3 all 3.9.19-1+jammy1 [127 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-distutils all 3.9.19-1+jammy1 [193 kB]\n",
            "Fetched 7,350 kB in 2s (3,149 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9:amd64.\n",
            "(Reading database ... 122417 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.9_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9:amd64 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9-dev:amd64.\n",
            "Preparing to unpack .../libpython3.9-dev_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-dev:amd64 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-dev.\n",
            "Preparing to unpack .../python3.9-dev_3.9.19-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-dev (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "Preparing to unpack .../python3.9-lib2to3_3.9.19-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.19-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../python3.9-distutils_3.9.19-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-lib2to3 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-distutils (3.9.19-1+jammy1) ...\n",
            "Setting up libpython3.9:amd64 (3.9.19-1+jammy1) ...\n",
            "Setting up libpython3.9-dev:amd64 (3.9.19-1+jammy1) ...\n",
            "Setting up python3.9-dev (3.9.19-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2574k  100 2574k    0     0  22.0M      0 --:--:-- --:--:-- --:--:-- 22.0M\n",
            "Collecting pip\n",
            "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-69.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "Using cached setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
            "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-24.0 setuptools-69.2.0 wheel-0.43.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2S5w8iO1H5g",
        "outputId": "31f80f2c-5852-40bf-fbec-44feaa9e1e9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --version"
      ],
      "metadata": {
        "id": "-kkALhEh5u-w",
        "outputId": "cd0086f7-003b-480f-9546-a80eb9b2c200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 24.0 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchtext==0.12.0 -f https://download.pytorch.org/whl/torch_stable.html --upgrade -q\n",
        "!pip install icevision[all] --upgrade --no-deps\n",
        "!pip install loguru --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h10lIYke0ywH",
        "outputId": "455665dd-5068-4437-827d-67a27f6285bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Cannot install torch==1.10.2+cu113, torchtext==0.12.0 and torchvision==0.11.3+cu113 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: icevision[all] in /usr/local/lib/python3.9/dist-packages (0.12.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: loguru in /usr/local/lib/python3.9/dist-packages (0.7.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0+cu113 torchvision==0.11.3+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ],
      "metadata": {
        "id": "z9pw9PHm65Rn",
        "outputId": "594c91fd-a9ae-402c-9f5d-d41bf42d1638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Using cached https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp39-cp39-linux_x86_64.whl (1637.0 MB)\n",
            "Requirement already satisfied: torchvision==0.11.3+cu113 in /usr/local/lib/python3.9/dist-packages (0.11.3+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.11.0+cu113) (4.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.11.3+cu113) (1.26.4)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==1.11.0+cu113 and torchvision==0.11.3+cu113 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.11.0+cu113\n",
            "    torchvision 0.11.3+cu113 depends on torch==1.10.2\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from icevision.all import *\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I-gfahc2EdH",
        "outputId": "61fdda7b-aaef-4791-8a18-57cd6f96694a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1mDownloading default `.ttf` font file - SpaceGrotesk-Medium.ttf from https://raw.githubusercontent.com/airctic/storage/master/SpaceGrotesk-Medium.ttf to /root/.icevision/fonts/SpaceGrotesk-Medium.ttf\u001b[0m | \u001b[36micevision.visualize.utils\u001b[0m:\u001b[36mget_default_font\u001b[0m:\u001b[36m67\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n"
      ],
      "metadata": {
        "id": "5fE1ph2a9SDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://github.com/experiencor/kangaroo -O kangaroo.zip\n",
        "!unzip kangaroo.zip"
      ],
      "metadata": {
        "id": "_gy845uP9Znf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=Path('kangaroo')\n"
      ],
      "metadata": {
        "id": "nGhPfrQ29img"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "id": "1r1V6KG39mE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parser"
      ],
      "metadata": {
        "id": "ScSsNU7a9tR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer paso es crear una plantilla para nuestro dataset."
      ],
      "metadata": {
        "id": "HUes_mqs9z7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_record = ObjectDetectionRecord()\n"
      ],
      "metadata": {
        "id": "4-pcb6kx9n8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación IceVision proporciona el método generate_template que nos proporciona los métodos que debemos implementar.\n",
        "\n"
      ],
      "metadata": {
        "id": "qNWX8wkQ91qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Parser.generate_template(template_record)\n"
      ],
      "metadata": {
        "id": "jCJYVHjI9qA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación vamos a implementar nuestra clase con cada uno de esos métodos.\n",
        "\n"
      ],
      "metadata": {
        "id": "eluT147c93Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la siguiente librería que nos servirá para leer ficheros XML\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class MyParser(Parser):\n",
        "    \"\"\"Definimos el constructor de nuestra clase que va a recibir cuatro parámetros:\n",
        "       - La plantilla definida previamente.\n",
        "       - El path al directorio donde se encuentran las imágenes.\n",
        "       - El path al directorio donde se encuentran las anotaciones.\n",
        "       - Un objeto class_map con las clases que tiene nuestro dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, template_record,path_img,path_anotaciones,class_map):\n",
        "        super().__init__(template_record=template_record)\n",
        "        self.path_img = path_img\n",
        "        self.path_anotaciones= path_anotaciones\n",
        "        self.class_map = class_map\n",
        "\n",
        "    \"\"\"El método iter escanea el directorio de anotaciones y nos devuelve el nombre\n",
        "    de cada fichero. Dicho nombre será utilizado por el resto de método\"\"\"\n",
        "    def __iter__(self):\n",
        "        with os.scandir(self.path_anotaciones) as ficheros:\n",
        "            for fichero in ficheros:\n",
        "                yield fichero.name\n",
        "\n",
        "    \"\"\"El método len nos indica el número de elementos de los que consta nuestro\n",
        "    dataset\"\"\"\n",
        "    def __len__(self):\n",
        "        return len(self.path_anotaciones)\n",
        "\n",
        "    \"\"\"A partir del nombre del fichero de anotación, record_id debe devolver el identificador\n",
        "    (o nombre) de la imagen asociada\"\"\"\n",
        "    def record_id(self, o) -> Hashable: #o --> nombre de la anotación\n",
        "        return o[:o.find('.')]\n",
        "\n",
        "    \"\"\"A continuación deberíamos definir el método parse_fields, pero vamos a definir una serie\n",
        "    de definiciones previas que nos serán útiles\"\"\"\n",
        "\n",
        "    \"\"\"El método prepare recibe el nombre de un fichero de anotación como parámetro y realiza\n",
        "    una serie de labores de preprocesamiento sobre dicho fichero de anotación. En este caso lo procesa\n",
        "    usando la funcionalidad de la librería para trabajar con xml\"\"\"\n",
        "    def prepare(self, o):\n",
        "        tree = ET.parse(str(self.path_anotaciones)+'/'+str(o))\n",
        "        self._root = tree.getroot()\n",
        "\n",
        "    \"\"\"El método filepath a partir del nombre del fichero de anotación devuelve el path de\n",
        "    la imagen asociada\"\"\"\n",
        "    def filepath(self, o) -> Union[str, Path]:\n",
        "        path=Path(f\"{o[:o.find('.')]}.jpg\")\n",
        "        return self.path_img / path\n",
        "\n",
        "    \"\"\"La función image_width_height devuelve el ancho y el alto de una imagen a partir del nombre\n",
        "    del fichero de anotación\"\"\"\n",
        "    def image_width_height(self, o) -> Tuple[int, int]:\n",
        "        return get_img_size(str(self.path_img)+'/'+f\"{o[:o.find('.')]}.jpg\")\n",
        "\n",
        "    \"\"\"La función labels recibe el nombre del fichero de anotación y debe devolver una lista\n",
        "    con los identificadores de las clases contenidas en dicho fichero.\"\"\"\n",
        "    def labels(self, o) -> List[int]:\n",
        "        labels = []\n",
        "        for object in self._root.iter(\"object\"):\n",
        "            label = object.find(\"name\").text\n",
        "            label_id = self.class_map.get_by_name(label)\n",
        "            labels.append(label)\n",
        "\n",
        "        return labels\n",
        "\n",
        "    \"\"\"La función bboxes recibe el nombre del fichero de anotación y debe devolver una lista\n",
        "    de bboxes que son las anotaciones contenidas en dicho fichero. El formato de cada BBOX es\n",
        "    xmin, ymin, xmax, ymax.\"\"\"\n",
        "    def bboxes(self, o) -> List[BBox]:\n",
        "        def to_int(x):\n",
        "            return int(float(x))\n",
        "\n",
        "        bboxes = []\n",
        "        for object in self._root.iter(\"object\"):\n",
        "            xml_bbox = object.find(\"bndbox\")\n",
        "            xmin = to_int(xml_bbox.find(\"xmin\").text)\n",
        "            ymin = to_int(xml_bbox.find(\"ymin\").text)\n",
        "            xmax = to_int(xml_bbox.find(\"xmax\").text)\n",
        "            ymax = to_int(xml_bbox.find(\"ymax\").text)\n",
        "\n",
        "            bbox = BBox.from_xyxy(xmin, ymin, xmax, ymax)\n",
        "            bboxes.append(bbox)\n",
        "\n",
        "        return bboxes\n",
        "\n",
        "\n",
        "    \"\"\"Definimos a continuación el método parse_fields para cada elemento de nuestro\n",
        "    dataset proporcionamos:\n",
        "       - El path a la imagen.\n",
        "       - El tamaño de la imagen.\n",
        "       - El mapa de clases.\n",
        "       - Los rectángulos que indican cada uno de los objetos de la imagen.\n",
        "       - Las etiquetas de cada uno de los objetos de la imagen.\"\"\"\n",
        "    def parse_fields(self, o: Any, record: BaseRecord, is_new: bool):\n",
        "        self.prepare(o)\n",
        "        if is_new:\n",
        "            record.set_filepath(self.filepath(o))\n",
        "            record.set_img_size(self.image_width_height(o))\n",
        "            record.detection.set_class_map(self.class_map)\n",
        "        record.detection.add_bboxes(self.bboxes(o))\n",
        "        record.detection.add_labels(self.labels(o))"
      ],
      "metadata": {
        "id": "6y6-RAsu95mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que hemos definido nuestra clase para parsear las anotaciones de nuestro dataset, vamos a construir los objetos correspondientes.\n",
        "\n",
        "Lo primero que tenemos que hacer es construir nuestro class_map que es un objeto de la clase ClassMap y que contiene las clases de objetos de nuestro dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "53PBrNeb98jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_map = ClassMap(['apple','banana','orange'])\n"
      ],
      "metadata": {
        "id": "KbYgHVfP96Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación definimos nuestros parsers. Uno para leer el conjunto de entrenamiento, y otro para el de test.\n",
        "\n"
      ],
      "metadata": {
        "id": "li01Ww959_SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainPath = Path('fruits')/'train'\n",
        "parserTrain = MyParser(template_record, trainPath/'images', trainPath/'labels', class_map)\n",
        "\n",
        "testPath = Path('fruits')/'test'\n",
        "parserTest = MyParser(template_record,testPath/'images', testPath/'labels', class_map)"
      ],
      "metadata": {
        "id": "zNzmL4Wh-A4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Records"
      ],
      "metadata": {
        "id": "5Iv7E6Dq-Iha"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Practica2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}